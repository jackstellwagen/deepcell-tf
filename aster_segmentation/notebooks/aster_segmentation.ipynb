{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Convolutional Interior/Edge Segmentation for 2D Data\n",
    "\n",
    "---\n",
    "\n",
    "Classifies each pixel as either Cell Edge, Cell Interior, or Background.\n",
    "\n",
    "There are 2 different Cell Edge classes (Cell-Cell Boundary and Cell-Background Boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import errno\n",
    "\n",
    "import os\n",
    "import errno\n",
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import deepcell.utils\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import deepcell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell.utils.data_utils import get_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "DATA_DIR2 = os.path.expanduser(\"/notebooks/aster_segmentation/datasets/\")\n",
    "filename2 = \"Aster_fullsize_2D.npz\"\n",
    "\n",
    "train_dict, test_dict = deepcell.utils.get_data(os.path.join(DATA_DIR2, filename2))\n",
    "X_train = train_dict['X'].astype(\"float64\")\n",
    "y_train = train_dict['y'].astype(\"float64\")\n",
    "X_test = test_dict['X'].astype(\"float64\")\n",
    "y_test = test_dict['y'].astype(\"float64\")\n",
    "\n",
    "\n",
    "#normalize each image to 0-256\n",
    "for i in range(X_train.shape[0]):\n",
    "    X_train[i] -= X_train[i].min()\n",
    "    X_train[i] *= 256./X_train[i].max()\n",
    "    \n",
    "for i in range(X_test.shape[0]):\n",
    "    X_test[i] -= X_test[i].min()\n",
    "    X_test[i] *= 256./X_test[i].max()\n",
    "\n",
    "\n",
    "#tile the dataset for bigger epochs\n",
    "X_new = np.tile(X_train, (15,1,1,1))\n",
    "y_new = np.tile(y_train, (15,1,1,1))\n",
    "\n",
    "new_filename = '/notebooks/aster_segmentation/datasets/example_tiled_2D.npz'\n",
    "np.savez(new_filename, X=X_new, y=y_new)\n",
    "filename='example_tiled_2D.npz'\n",
    "\n",
    "#print('X.shape: {}\\ny.shape: {}'.format(X_train.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up filepath constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path to the data file is currently required for `train_model_()` functions\n",
    "DATA_DIR = os.path.expanduser('/notebooks/aster_segmentation/datasets/')\n",
    "filename='example_tiled_2D.npz'\n",
    "\n",
    "\n",
    "# NOTE: Change DATA_DIR if you are not using `deepcell.datasets`\n",
    "# DATA_DIR = os.path.expanduser(os.path.join('~', '.keras', 'datasets'))\n",
    "\n",
    "DATA_FILE = os.path.join(DATA_DIR, filename)\n",
    "\n",
    "# confirm the data file is available\n",
    "assert os.path.isfile(DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up other required filepaths\n",
    "\n",
    "# If the data file is in a subdirectory, mirror it in MODEL_DIR and LOG_DIR\n",
    "PREFIX = os.path.relpath(os.path.dirname(DATA_FILE), DATA_DIR)\n",
    "\n",
    "ROOT_DIR = '/notebooks/aster_segmentation/saved_networks'  # TODO: Change this! Usually a mounted volume\n",
    "MODEL_DIR = os.path.abspath(os.path.join(ROOT_DIR, 'models', PREFIX))\n",
    "LOG_DIR = os.path.abspath(os.path.join(ROOT_DIR, 'logs', PREFIX))\n",
    "\n",
    "# create directories if they do not exist\n",
    "for d in (MODEL_DIR, LOG_DIR):\n",
    "    try:\n",
    "        os.makedirs(d)\n",
    "    except OSError as exc:  # Guard against race condition\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "from deepcell.utils.train_utils import rate_scheduler\n",
    "\n",
    "fgbg_model_name = 'conv_model_std_61_test'\n",
    "\n",
    "n_epoch = 1  # Number of training epochs\n",
    "test_size = .10  # % of data saved as test\n",
    "norm_method = \"std\"  # data normalization\n",
    "receptive_field = 61  # should be adjusted for the scale of the data\n",
    "\n",
    "optimizer = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "lr_sched = rate_scheduler(lr=0.01, decay=0.99)\n",
    "\n",
    "# FC training settings\n",
    "n_skips = 2  # number of skip-connections (only for FC training)\n",
    "batch_size = 1  # FC training uses 1 image per batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, create a foreground/background separation model\n",
    "\n",
    "#### Instantiate the fgbg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell import model_zoo\n",
    "\n",
    "fgbg_model = model_zoo.bn_feature_net_skip_2D(\n",
    "    n_features=3,\n",
    "    receptive_field=receptive_field,\n",
    "    n_skips=n_skips,\n",
    "    n_conv_filters=32,\n",
    "    n_dense_filters=128,\n",
    "    norm_method = norm_method,\n",
    "    input_shape=(None, None, 1),\n",
    "    last_only=False)\n",
    "\n",
    "#fgbg_model.load_weights(\"/notebooks/aster_segmentation/saved_networks/models/conv_model_std_61.h5\") #load in a pretrained netowork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model fgbg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4185, 240, 384, 1)\n",
      "y_train shape: (4185, 240, 384, 1)\n",
      "X_test shape: (465, 240, 384, 1)\n",
      "y_test shape: (465, 240, 384, 1)\n",
      "Output Shape: (None, None, None, 3)\n",
      "Number of Classes: 3\n",
      "Training on 2 GPUs\n",
      "Epoch 1/1\n",
      "2091/2092 [============================>.] - ETA: 0s - loss: 1.3981 - model_loss: 0.4712 - model_1_loss: 0.4579 - model_2_loss: 0.4403 - model_acc: 0.9190 - model_1_acc: 0.9182 - model_2_acc: 0.9209\n",
      "Epoch 00001: val_loss improved from inf to 4.10375, saving model to /notebooks/aster_segmentation/saved_networks/models/conv_model_std_61_test.h5\n",
      "2092/2092 [==============================] - 1056s 505ms/step - loss: 1.3977 - model_loss: 0.4711 - model_1_loss: 0.4578 - model_2_loss: 0.4402 - model_acc: 0.9191 - model_1_acc: 0.9182 - model_2_acc: 0.9209 - val_loss: 4.1037 - val_model_loss: 2.0813 - val_model_1_loss: 1.0401 - val_model_2_loss: 0.9525 - val_model_acc: 0.9558 - val_model_1_acc: 0.9562 - val_model_2_acc: 0.9572\n"
     ]
    }
   ],
   "source": [
    "from deepcell.training import train_model_conv\n",
    "\n",
    "fgbg_model = train_model_conv(\n",
    "    model=fgbg_model,\n",
    "    dataset=DATA_FILE,  # full path to npz file\n",
    "    model_name=fgbg_model_name,\n",
    "    test_size=test_size,\n",
    "    optimizer=optimizer,\n",
    "    n_epoch=n_epoch,\n",
    "    batch_size=batch_size,\n",
    "    transform=None,\n",
    "    model_dir=MODEL_DIR,\n",
    "    log_dir=LOG_DIR,\n",
    "    lr_sched=lr_sched,\n",
    "    rotation_range=180,\n",
    "    flip=True,\n",
    "    shear=False,\n",
    "    zoom_range=(0.8, 1.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model\n",
    "\n",
    "#### Make predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = fgbg_model.predict(X_test)[-1]\n",
    "\n",
    "# np.savez( \"/notebooks/docker_hole/deepcell-tf/output.npz\", predicted = test_images, source = X_test, ground_truth =y_test)\n",
    "# npzfile = np.load(\"/notebooks/docker_hole/deepcell-tf/output.npz\")\n",
    "# print(npzfile.files)\n",
    "\n",
    "print('mask shape:', test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = np.random.randint(low=0, high=X_test.shape[0])\n",
    "#index = 24\n",
    "print('Image number:', index)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(15, 15), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(X_test[index, ..., 0], cmap=\"gray\")\n",
    "ax[0].set_title('Source Image')\n",
    "\n",
    "ax[1].imshow(np.argmax(test_images[index], axis=-1))\n",
    "ax[1].set_title('Prediction')\n",
    "\n",
    "#ax[2].imshow(np.squeeze(test_dict['y'][index]))\n",
    "ax[2].imshow(np.squeeze(y_test[index]))\n",
    "ax[2].set_title('Ground Truth')\n",
    "\n",
    "print(y_test[24][125][220])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65535.0 1398.0 (179, 240, 384, 1)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import skimage.transform\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "def check_val(name):\n",
    "    num = \"\"\n",
    "    for i in range(0,8):\n",
    "        if name[i].isdigit():\n",
    "            num += name[i]\n",
    "    return int(num)\n",
    "\n",
    "def file_sort(tif_arr):\n",
    "    new_arr = [0]*len(tif_arr)\n",
    "    for i in range(len(tif_arr)):\n",
    "        new_arr[check_val(tif_arr[i])-1] = tif_arr[i]\n",
    "    return new_arr\n",
    "\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "#make sure to create an annotated_movies directory and download Zijie_Demo_ideo\n",
    "base_dir= '/notebooks/aster_segmentation/Zijie_demo_Video/600um_length/'\n",
    "file = \"600_AR_0.75\"\n",
    "image_folder = os.path.join(base_dir,file)\n",
    "video_name = os.path.join(\"/notebooks/aster_segmentation/annotated_movies/\", file+\"_annotated.avi\" )\n",
    "\n",
    "\n",
    "\n",
    "images = [img for img in os.listdir(image_folder) if img.endswith(\".tif\")]\n",
    "#print(images)\n",
    "images = file_sort(images)\n",
    "#print(images)\n",
    "\n",
    "image_arr = []\n",
    "for i in range(len(images)):\n",
    "    image_arr.append(np.array(Image.open(os.path.join(image_folder, images[i]))))\n",
    "    \n",
    "\n",
    "image_arr = np.array(image_arr)[...,np.newaxis].astype(\"float64\")\n",
    "#print(image_arr.min(axis = 0))\n",
    "#image_arr = ((image_arr - image_arr.min(axis = 0)) /image_arr.max(axis = 0)) *65535\n",
    "\n",
    "image_arr = skimage.transform.resize(image_arr, (image_arr.shape[0],240,384,1), anti_aliasing=False)\n",
    "\n",
    "print(image_arr.max(), image_arr.min(), image_arr.shape)\n",
    "image_arr = (image_arr/256).astype(\"float32\")\n",
    "\n",
    "for i in range(image_arr.shape[0]):\n",
    "    image_arr[i] -= image_arr[i].min()\n",
    "    image_arr[i] *= 256./image_arr[i].max()\n",
    "\n",
    "predicted_images = fgbg_model.predict(image_arr)[-1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "frame = predicted_images[0]\n",
    "height, width, layers = frame.shape\n",
    "\n",
    "video = cv2.VideoWriter(video_name, 0, 10, (width,height))\n",
    "\n",
    "for i in range(predicted_images.shape[0]):\n",
    "    video.write(cv2.cvtColor(np.argmax(predicted_images[i], axis=-1).astype(\"uint8\")*100,cv2.COLOR_GRAY2RGB))\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "video.release()\n",
    "print(time.time()-start)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
